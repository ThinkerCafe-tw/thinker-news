#!/usr/bin/env python3
"""
Thinker News æ¯æ—¥æ–°èè‡ªå‹•ç”Ÿæˆç³»çµ±
å¾ n8n é·ç§»åˆ° GitHub Actions

æ ¸å¿ƒæµç¨‹ï¼š
1. è®€å– RSS feeds
2. å°ç£æœ¬åœ°åŒ–ç¯©é¸
3. AI è™•ç†éˆï¼ˆGemini â†’ OpenAI â†’ OpenAIï¼‰
4. ç”Ÿæˆ HTML é é¢
5. æ›´æ–° GitHub repo
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('news_generation.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from rss_fetcher import fetch_all_rss_feeds
from news_filter import filter_and_score_news
from ai_processor import (
    setup_apis,
    process_with_data_alchemist,
    process_with_tech_narrator,
    process_with_editor_in_chief
)
from html_generator import generate_daily_html, update_index_html
from utils import get_taiwan_date, validate_json_output


def main():
    """ä¸»åŸ·è¡Œæµç¨‹"""
    try:
        # ============================================
        # æ­¥é©Ÿ 0: è¨­ç½® API Keys
        # ============================================
        logger.info("ğŸ”‘ è¨­ç½® API Keys...")
        openai_client = setup_apis()
        logger.info("âœ… API Keys è¨­ç½®å®Œæˆ")

        # ============================================
        # æ­¥é©Ÿ 1: ç”Ÿæˆä»Šæ—¥æ—¥æœŸï¼ˆå°ç£æ™‚å€ï¼‰
        # ============================================
        today_date = get_taiwan_date()
        logger.info(f"ğŸ“… ç”Ÿæˆä»Šæ—¥æ—¥æœŸ: {today_date}")
        
        # ============================================
        # æ­¥é©Ÿ 2: è®€å–æ‰€æœ‰ RSS feeds
        # ============================================
        logger.info("ğŸ“¡ é–‹å§‹è®€å– RSS feeds...")
        all_feeds = fetch_all_rss_feeds(today_date)
        logger.info(f"âœ… æˆåŠŸè®€å– {len(all_feeds)} å‰‡æ–°è")
        
        # ============================================
        # æ­¥é©Ÿ 3: å°ç£æœ¬åœ°åŒ–ç¯©é¸èˆ‡è©•åˆ†
        # ============================================
        logger.info("ğŸ” åŸ·è¡Œå°ç£æœ¬åœ°åŒ–ç¯©é¸...")
        filtered_news = filter_and_score_news(all_feeds, today_date)
        logger.info(f"âœ… ç¯©é¸å¾Œä¿ç•™ {len(filtered_news)} å‰‡æ–°è")
        
        if len(filtered_news) == 0:
            logger.error("âŒ æ²’æœ‰æ–°èé€šéç¯©é¸ï¼Œæµç¨‹çµ‚æ­¢")
            sys.exit(1)
        
        # ============================================
        # æ­¥é©Ÿ 4: AI è™•ç†éˆ
        # ============================================
        logger.info("ğŸ¤– é–‹å§‹ AI è™•ç†éˆ...")
        
        # 4.1 æ•¸æ“šç…‰é‡‘è¡“å¸« (Gemini)
        logger.info("  âš—ï¸  æ•¸æ“šç…‰é‡‘è¡“å¸«è™•ç†ä¸­...")
        alchemist_output = process_with_data_alchemist(filtered_news, today_date)
        alchemist_json = validate_json_output(alchemist_output, "æ•¸æ“šç…‰é‡‘è¡“å¸«")
        
        # 4.2 ç§‘æŠ€å°è®€äºº (OpenAI)
        logger.info("  ğŸ“° ç§‘æŠ€å°è®€äººè™•ç†ä¸­...")
        narrator_output = process_with_tech_narrator(alchemist_json, today_date)
        narrator_json = validate_json_output(narrator_output, "ç§‘æŠ€å°è®€äºº")
        
        # 4.3 ç¸½ç·¨è¼¯ (OpenAI)
        logger.info("  âœï¸  ç¸½ç·¨è¼¯è™•ç†ä¸­...")
        editor_output = process_with_editor_in_chief(narrator_json, today_date)
        editor_json = validate_json_output(editor_output, "ç¸½ç·¨è¼¯")
        
        logger.info("âœ… AI è™•ç†éˆå®Œæˆ")
        
        # ============================================
        # æ­¥é©Ÿ 5: çµ„è£æœ€çµ‚è¼¸å‡º
        # ============================================
        logger.info("ğŸ“¦ çµ„è£æœ€çµ‚è¼¸å‡º...")
        
        notion_content = narrator_json.get('notion_daily_report_text', '')
        line_content = editor_json.get('line_message_text', '')
        website_url = f"https://thinkercafe-tw.github.io/thinker-news/{today_date}.html"
        
        final_output = {
            'final_date': today_date,
            'notion_content': notion_content,
            'line_content': line_content,
            'website_url': website_url,
            'news_json': {
                'date': today_date,
                'line_content': line_content,
                'notion_content': notion_content,
                'website_url': website_url,
                'generated_at': datetime.now().isoformat()
            }
        }
        
        # ============================================
        # æ­¥é©Ÿ 6: ç”Ÿæˆ HTML æ–‡ä»¶
        # ============================================
        logger.info("ğŸ“ ç”Ÿæˆ HTML æ–‡ä»¶...")
        
        # 6.1 ç”Ÿæˆä»Šæ—¥æ–°èé é¢
        daily_html_path = generate_daily_html(final_output)
        logger.info(f"âœ… ä»Šæ—¥æ–°èé é¢: {daily_html_path}")
        
        # 6.2 æ›´æ–°é¦–é  index.html
        index_html_path = update_index_html(today_date)
        logger.info(f"âœ… é¦–é æ›´æ–°: {index_html_path}")
        
        # ============================================
        # æ­¥é©Ÿ 7: å„²å­˜ latest.json
        # ============================================
        logger.info("ğŸ’¾ å„²å­˜ latest.json...")
        latest_json_path = Path('latest.json')
        with open(latest_json_path, 'w', encoding='utf-8') as f:
            json.dump(final_output['news_json'], f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… latest.json å·²å„²å­˜")
        
        # ============================================
        # å®Œæˆ
        # ============================================
        logger.info("ğŸ‰ æ–°èç”Ÿæˆæµç¨‹å®Œæˆï¼")
        logger.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š:")
        logger.info(f"  - åŸå§‹æ–°èæ•¸: {len(all_feeds)}")
        logger.info(f"  - ç¯©é¸å¾Œæ•¸é‡: {len(filtered_news)}")
        logger.info(f"  - ç”Ÿæˆæ—¥æœŸ: {today_date}")
        logger.info(f"  - ç¶²ç«™ URL: {website_url}")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
