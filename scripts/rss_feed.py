"""
RSS Feed ç”Ÿæˆæ¨¡çµ„
ç”¢ç”Ÿ RSS 2.0 XML feedï¼Œè®“è®€è€…å¯ä»¥é€é RSS é–±è®€å™¨è¨‚é–± Thinker Newsã€‚

è¼¸å‡ºæª”æ¡ˆï¼šfeed.xmlï¼ˆæ ¹ç›®éŒ„ï¼‰
"""

import re
import json
from pathlib import Path
from datetime import datetime, timezone, timedelta
from xml.etree.ElementTree import Element, SubElement, tostring, indent

from log_config import get_logger
logger = get_logger(__name__)

# ç«™é»è³‡è¨Š
SITE_URL = "https://thinkercafe-tw.github.io/thinker-news"
SITE_NAME = "Thinker News â€” AI ç§‘æŠ€æ—¥å ±"
SITE_DESCRIPTION = "æ¯æ—¥ç²¾é¸ AI ç§‘æŠ€æ–°èï¼Œå°ˆç‚ºè³‡æ–™ç§‘å­¸åˆå­¸è€…è¨­è¨ˆã€‚æ¶µè“‹ AI å·¥å…·ã€ç”¢æ¥­è¶¨å‹¢ã€è³‡å®‰å¿«è¨Šèˆ‡è·æ¶¯è§€å¯Ÿã€‚"
FEED_FILENAME = "feed.xml"
MAX_ITEMS = 20  # RSS feed æœ€å¤šåˆ—å¹¾ç¯‡

# æ™‚å€
TW_TZ = timezone(timedelta(hours=8))


def _extract_title_from_html(html_path: Path) -> str:
    """å¾ HTML çš„ <title> æ¨™ç±¤æå–æ¨™é¡Œ"""
    try:
        content = html_path.read_text(encoding="utf-8")
        m = re.search(r"<title>(.*?)</title>", content, re.DOTALL)
        if m:
            title = m.group(1).strip()
            # ç§»é™¤å°¾å·´çš„ " | Thinker News"
            title = re.sub(r"\s*\|\s*Thinker News$", "", title)
            return title
    except Exception:
        pass
    return None


def _extract_description_from_html(html_path: Path) -> str:
    """å¾ HTML çš„ meta description æå–æ‘˜è¦"""
    try:
        content = html_path.read_text(encoding="utf-8")
        m = re.search(
            r'<meta\s+name=["\']description["\']\s+content=["\'](.*?)["\']',
            content,
            re.DOTALL | re.IGNORECASE,
        )
        if m:
            return m.group(1).strip()
    except Exception:
        pass
    return None


def _scan_reports() -> list:
    """
    æƒæ archive/ ç›®éŒ„ + æ ¹ç›®éŒ„ï¼Œæ”¶é›†æ‰€æœ‰æ—¥å ± HTMLã€‚

    Returns:
        list of dictï¼ŒæŒ‰æ—¥æœŸå€’åºæ’åˆ—ï¼š
        [{'date': '2026-02-11', 'path': Path(...), 'url': '...'}, ...]
    """
    date_pattern = re.compile(r"^(\d{4}-\d{2}-\d{2})\.html$")
    reports = []

    # æƒæ archive/
    archive_dir = Path("archive")
    if archive_dir.exists():
        for f in archive_dir.iterdir():
            m = date_pattern.match(f.name)
            if m:
                reports.append({
                    "date": m.group(1),
                    "path": f,
                    "url": f"{SITE_URL}/archive/{f.name}",
                })

    # æƒææ ¹ç›®éŒ„ï¼ˆä»Šæ—¥å¯èƒ½é‚„æ²’ç§»å…¥ archive/ï¼‰
    for f in Path(".").iterdir():
        m = date_pattern.match(f.name)
        if m and m.group(1) not in {r["date"] for r in reports}:
            reports.append({
                "date": m.group(1),
                "path": f,
                "url": f"{SITE_URL}/{f.name}",
            })

    reports.sort(key=lambda r: r["date"], reverse=True)
    return reports[:MAX_ITEMS]


def generate_rss_feed() -> str:
    """
    ç”¢ç”Ÿ RSS 2.0 feed.xmlã€‚

    Returns:
        è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    logger.info("ğŸ“¡ ç”¢ç”Ÿ RSS feed...")

    reports = _scan_reports()
    if not reports:
        logger.warning("âš ï¸  æ‰¾ä¸åˆ°ä»»ä½•æ—¥å ± HTMLï¼Œè·³é RSS ç”Ÿæˆ")
        return None

    # å»ºæ§‹ XML
    rss = Element("rss", version="2.0")
    rss.set("xmlns:atom", "http://www.w3.org/2005/Atom")
    channel = SubElement(rss, "channel")

    # Channel metadata
    SubElement(channel, "title").text = SITE_NAME
    SubElement(channel, "link").text = SITE_URL
    SubElement(channel, "description").text = SITE_DESCRIPTION
    SubElement(channel, "language").text = "zh-TW"
    SubElement(channel, "lastBuildDate").text = datetime.now(TW_TZ).strftime(
        "%a, %d %b %Y %H:%M:%S %z"
    )
    SubElement(channel, "generator").text = "Thinker News RSS Generator"

    # Atom self-linkï¼ˆRSS æœ€ä½³å¯¦è¸ï¼‰
    atom_link = SubElement(channel, "atom:link")
    atom_link.set("href", f"{SITE_URL}/{FEED_FILENAME}")
    atom_link.set("rel", "self")
    atom_link.set("type", "application/rss+xml")

    # å˜—è©¦å¾ latest.json å–å¾—æœ€æ–°ä¸€ç¯‡çš„è±å¯Œæ‘˜è¦
    latest_summary = {}
    latest_json = Path("latest.json")
    if latest_json.exists():
        try:
            data = json.loads(latest_json.read_text(encoding="utf-8"))
            latest_summary[data.get("date", "")] = data.get("line_content", "")
        except Exception:
            pass

    # Items
    for report in reports:
        item = SubElement(channel, "item")

        date_str = report["date"]

        # æ¨™é¡Œ
        title = _extract_title_from_html(report["path"])
        if not title:
            title = f"{date_str} AI ç§‘æŠ€æ—¥å ±"
        SubElement(item, "title").text = title

        # é€£çµ
        SubElement(item, "link").text = report["url"]

        # GUID
        guid = SubElement(item, "guid")
        guid.set("isPermaLink", "true")
        guid.text = report["url"]

        # ç™¼ä½ˆæ—¥æœŸï¼ˆå‡è¨­æ¯æ—¥ 08:30 ç™¼ä½ˆï¼‰
        try:
            pub_dt = datetime.strptime(date_str, "%Y-%m-%d").replace(
                hour=8, minute=30, tzinfo=TW_TZ
            )
            SubElement(item, "pubDate").text = pub_dt.strftime(
                "%a, %d %b %Y %H:%M:%S %z"
            )
        except ValueError:
            pass

        # æ‘˜è¦ï¼šå„ªå…ˆç”¨ latest.json å…§å®¹ï¼Œå…¶æ¬¡ç”¨ meta description
        description = ""
        if date_str in latest_summary:
            description = latest_summary[date_str]
        else:
            meta_desc = _extract_description_from_html(report["path"])
            if meta_desc:
                description = meta_desc

        if description:
            SubElement(item, "description").text = description

        # åˆ†é¡
        SubElement(item, "category").text = "AI ç§‘æŠ€æ–°è"

    # æ ¼å¼åŒ– XML
    indent(rss, space="  ")
    xml_bytes = tostring(rss, encoding="unicode", xml_declaration=False)
    xml_content = '<?xml version="1.0" encoding="UTF-8"?>\n' + xml_bytes

    # å¯«å…¥
    output_path = Path(FEED_FILENAME)
    output_path.write_text(xml_content, encoding="utf-8")

    logger.info(f"âœ… RSS feed å·²ç”Ÿæˆ: {output_path}ï¼ˆ{len(reports)} ç¯‡æ–‡ç« ï¼‰")
    return str(output_path)


if __name__ == "__main__":
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    result = generate_rss_feed()
    if result:
        print(f"RSS feed generated: {result}")
    else:
        print("No reports found, feed not generated.")
