"""
å°ç£æœ¬åœ°åŒ–æ–°èç¯©é¸å™¨
ç§»æ¤è‡ª n8n workflow çš„ Code3 ç¯€é»

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ™ºèƒ½è©•åˆ†ç³»çµ±
2. å°ç£è¦–è§’å„ªå…ˆ
3. ä¾†æºå¹³è¡¡ç­–ç•¥

ç¯©é¸é…ç½®è¦‹ filter_config.py
"""

import logging
from datetime import datetime, timedelta
from typing import List, Dict

from filter_config import (
    SOURCES, TAIWAN_SOURCES, INTERNATIONAL_SOURCES,
    TAIWAN_INTERESTS, GLOBAL_TAIWAN_FOCUS,
    MUST_KEEP_PHRASES, PRACTICAL_KEYWORDS,
    SOURCE_LABELS,
)

logger = logging.getLogger(__name__)


def calculate_relevance(item: Dict) -> int:
    """
    è¨ˆç®—æ–°èçš„ç›¸é—œæ€§åˆ†æ•¸

    Args:
        item: æ–°èé …ç›®

    Returns:
        ç›¸é—œæ€§åˆ†æ•¸
    """
    title = item.get('title', '').lower()
    content = item.get('content', '').lower()
    full_text = f"{title} {content}"

    source = item.get('source', 'unknown')
    config = SOURCES.get(source, {
        'priority_keywords': [],
        'exclude': [],
        'base_score': 0
    })

    score = config.get('base_score', 0)

    # 1. å¿…é ˆä¿ç•™
    for phrase in MUST_KEEP_PHRASES:
        if phrase.lower() in full_text:
            return 100

    # 2. æ’é™¤é—œéµå­—
    for keyword in config.get('exclude', []):
        if keyword.lower() in full_text:
            score -= 5

    # 3. ä¾†æºå„ªå…ˆé—œéµå­—
    for keyword in config.get('priority_keywords', []):
        keyword_lower = keyword.lower()
        if keyword_lower in title:
            score += 10
        elif keyword_lower in content:
            score += 5

    # 4. å°ç£èˆˆè¶£é—œéµå­—ï¼ˆé¡å¤–åŠ åˆ†ï¼‰
    for keyword in TAIWAN_INTERESTS:
        if keyword.lower() in full_text:
            score += 4

    # 5. å…¨çƒä½†å°ç£é—œæ³¨çš„ä¸»é¡Œ
    for keyword in GLOBAL_TAIWAN_FOCUS:
        if keyword.lower() in full_text:
            score += 6

    # 6. ä¾†æºé¡å‹åŠ åˆ†
    if source in TAIWAN_SOURCES:
        score += 5
        if 'åœ‹éš›' in full_text or 'global' in full_text:
            score += 8

    if source in INTERNATIONAL_SOURCES:
        if 'taiwan' in full_text or 'asia' in full_text:
            score += 10

    # 7. å¯¦ç”¨æ€§åŠ åˆ†
    for keyword in PRACTICAL_KEYWORDS:
        if keyword in title:
            score += 7

    # 8. å…§å®¹é•·åº¦
    if len(content) > 300:
        score += 2
    if len(content) > 500:
        score += 2

    return score


def filter_and_score_news(all_news: List[Dict], target_date: str) -> List[Dict]:
    """
    ç¯©é¸å’Œè©•åˆ†æ–°è

    Args:
        all_news: æ‰€æœ‰æ–°èåˆ—è¡¨
        target_date: ç›®æ¨™æ—¥æœŸ

    Returns:
        ç¯©é¸å¾Œçš„æ–°èåˆ—è¡¨
    """
    logger.info("ğŸ” é–‹å§‹ç¯©é¸æ–°è...")

    # è§£æç›®æ¨™æ—¥æœŸ
    target_dt = datetime.strptime(target_date, '%Y-%m-%d')
    yesterday = target_dt - timedelta(days=1)
    yesterday_str = yesterday.strftime('%Y-%m-%d')

    # åˆ†çµ„è™•ç†
    grouped = {source: [] for source in SOURCES}
    grouped['unknown'] = []

    for item in all_news:
        # æª¢æŸ¥æ—¥æœŸ
        pub_date = item.get('isoDate', '')
        if pub_date:
            try:
                pub_dt = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                if pub_dt.strftime('%Y-%m-%d') != yesterday_str:
                    continue
            except Exception:
                continue

        # è¨ˆç®—åˆ†æ•¸
        score = calculate_relevance(item)
        source = item.get('source', 'unknown')

        # æ·»åŠ é¡å¤–è³‡è¨Š
        enriched_item = {
            **item,
            'relevance_score': score,
            'source_label': SOURCE_LABELS.get(source, 'ğŸ“° å…¶ä»–')
        }

        if source in grouped:
            grouped[source].append(enriched_item)
        else:
            grouped['unknown'].append(enriched_item)

    # æ’åºå’Œé™åˆ¶
    taiwan_news = []
    international_news = []

    for source, items in grouped.items():
        if not items or source == 'unknown':
            continue

        config = SOURCES.get(source, {})
        max_items = config.get('max_items', 5)

        # æ’åºä¸¦ç¯©é¸
        filtered = sorted(items, key=lambda x: x['relevance_score'], reverse=True)
        filtered = [item for item in filtered if item['relevance_score'] > 0]
        filtered = filtered[:max_items]

        # åˆ†é¡æœ¬åœ°èˆ‡åœ‹éš›
        if source in TAIWAN_SOURCES:
            taiwan_news.extend(filtered)
        else:
            international_news.extend(filtered)

        logger.info(f"  {SOURCE_LABELS.get(source, source)}: {len(items)} â†’ {len(filtered)}")

    # æ··åˆæ’åºç­–ç•¥ï¼šç¢ºä¿æœ¬åœ°èˆ‡åœ‹éš›æ–°èå¹³è¡¡
    final_items = []
    max_length = max(len(taiwan_news), len(international_news))

    for i in range(max_length):
        if i < len(taiwan_news):
            final_items.append(taiwan_news[i])
        if i < len(international_news):
            final_items.append(international_news[i])

    # æœ€çµ‚æŒ‰åˆ†æ•¸é‡æ’ï¼ˆä½†ä¿æŒä¸€å®šå¤šæ¨£æ€§ï¼‰
    final_items.sort(key=lambda x: (
        # å…ˆæŒ‰åˆ†æ•¸åˆ†çµ„
        -1 if x['relevance_score'] > 20 else (-2 if x['relevance_score'] > 10 else -3),
        # åŒçµ„å…§æŒ‰åˆ†æ•¸æ’åº
        -x['relevance_score']
    ))

    # çµ±è¨ˆå ±å‘Š
    logger.info("\nğŸ“Š ç¯©é¸çµæœç¸½è¦½ï¼š")
    logger.info("ã€å°ç£æ–°èã€‘")
    for source in TAIWAN_SOURCES:
        count = len([item for item in final_items if item['source'] == source])
        logger.info(f"  {SOURCE_LABELS[source]}: {count} å‰‡")

    logger.info("\nã€åœ‹éš›æ–°èã€‘")
    for source in INTERNATIONAL_SOURCES:
        count = len([item for item in final_items if item['source'] == source])
        logger.info(f"  {SOURCE_LABELS[source]}: {count} å‰‡")

    taiwan_count = len([i for i in final_items if i['source'] in TAIWAN_SOURCES])
    international_count = len(final_items) - taiwan_count

    logger.info(f"\n{'=' * 40}")
    logger.info(f"âœ… æœ€çµ‚ä¿ç•™: {len(final_items)} å‰‡")
    logger.info(f"  - æœ¬åœ°: {taiwan_count} å‰‡")
    logger.info(f"  - åœ‹éš›: {international_count} å‰‡")
    logger.info(f"{'=' * 40}\n")

    return final_items
